{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec8774f3",
   "metadata": {},
   "source": [
    "# DNN\n",
    "fashion MNIST 데이터 셋을 활용해 classification을 해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcfc04f",
   "metadata": {},
   "source": [
    "2️⃣ DNN을 통해 Fashion MNIST Data 분류하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "91169fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51c41d4",
   "metadata": {},
   "source": [
    "tensor와 가중치에 대한 연산을 CPU와 GPU 중 어디서 실행할지 결정한다.  \n",
    "코드 공유 시에 유용하므로 항상 아래 코드를 포함하도록 하자.\n",
    "\n",
    "cuda인 경우 GPU에서, cpu인 경우는 cpu에서 실행된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e248338f",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available() # cuda 사용 여부\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d1e03a",
   "metadata": {},
   "source": [
    "Fashion MNIST는 70,000개로 구성되어 그 수가 많다.  \n",
    "따라서 Batch size 단위로 나누어 학습시키자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a47c896c",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30 # 학습과 평가를 epoch 만큼 진행\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c39699",
   "metadata": {},
   "source": [
    "## DNN Structure\n",
    "\n",
    "### Model class\n",
    "- torch.nn 상속 Class 정의\n",
    "    - 생성자에서 각 layer에서 이뤄질 작업을 초기화한다.\n",
    "    - forward 함수에 forward propagation에 진행될 작업을 정의한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58e73c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 10) # output layer ; multi-class classification\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784) # 1차원 행렬로 변환\n",
    "        x = F.relu(self.fc1(x))        \n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba359965",
   "metadata": {},
   "source": [
    "nn.ReLu와 F.relu는 같은 기능을 제공한다. 따라서 원하는 것을 사용해도 된다.   \n",
    "단, torch.nn.functional은 가중치 없는 연산을, torch.nn 모듈은 가중치 있는 연산을 할 때 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595e012b",
   "metadata": {},
   "source": [
    "#### Model Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3ef3baf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(DEVICE) # 지정된 장치의 메모리로 전달"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bbefd86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc11cb13",
   "metadata": {},
   "source": [
    "### Train 함수 정의\n",
    "모델의 훈련은 오차를 최소화하기 위해 가중치와 편향을 조정하는 과정이다. Train 함수에 다음의 과정을 정의하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28722208",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer):\n",
    "    model.train() # train mode\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # 학습 데이터를 DEVICE의 메모리로 보냄\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(data)\n",
    "        \n",
    "        loss = F.cross_entropy(output, target) # batch size인 64개 loss의 평균값이 return된다.\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f866ff79",
   "metadata": {},
   "source": [
    "- train_loader : 데이터를 공급하는 매개변수  \n",
    "    (data, target) 형식의 배치를 반환한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98d46ea",
   "metadata": {},
   "source": [
    "### Evaluation 함수 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e0ba27",
   "metadata": {},
   "source": [
    "#### 모델 성능 평가\n",
    "\n",
    "- 일반화 성능  \n",
    "    훈련 데이터 뿐 아니라 모든 데이터에 대해 적용 가능해야 한다.\n",
    "    \n",
    "매 epoch가 끝날 때마다 모델을 평가하는 함수를 만들어 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0334004b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    model.eval() # evaluation mode\n",
    "    \n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    # 평가 과정에는 기울기 계산이 필요 없다.\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "            output = model(data) #예측 값\n",
    "            \n",
    "            # test 오차의 합\n",
    "            test_loss += F.cross_entropy(output, target,\n",
    "                                        reduction='sum').item()\n",
    "            # 모델의 예측이 맞은 개수\n",
    "            pred = output.max(1, keepdim=True)[1] #예측한 index\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "        # 오차 평균\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        #accuracy\n",
    "        test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "            \n",
    "        return test_loss, test_accuracy\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b09b45e",
   "metadata": {},
   "source": [
    "- output.max()는 가장 큰 값과, 그 인덱스 2개의 값을 return한다.  \n",
    "  우리는 모델이 예측한 레이블이 뭔지 궁금한 것이므로 두 번째 값인 인덱스 값을 반환하도록 한다.\n",
    "  > argmax 함수 : 배열에서 가장 큰 값이 있는 인덱스를 반환하는 함수\n",
    "\n",
    "\n",
    "- pred.eq(target.view_as(pred)).sum().item()\n",
    "    - target.view_as(pred) : target을 pred와 형태를 일치시켜 비교하도록 한다.  \n",
    "    - eq() : target값과 일치하면 1을, 일치하지 않으면 0을 반환하므로 sum()을 통해 정답을 맞춘 개수를 구할 수 있다. \n",
    "    \n",
    "위 정보를 통해 accuracy를 구할 수 있겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a768eb4e",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "신경망 모델을 실행하기 위한 준비는 다 끝났다. 이제 fashionMNIST 데이터를 로드해 실제로 돌려보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06069a9",
   "metadata": {},
   "source": [
    "#### import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b1f06fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms, utils # 이미지 데이터 조작\n",
    "from torch.utils import data # 데이터 로드 및 조작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a1f4c625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로드할 data에 적용할 filters\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor() # tensor로 변형\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4833068",
   "metadata": {},
   "source": [
    "#### 로드할 data 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2521130d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = datasets.FashionMNIST(\n",
    "    root = './.data/',\n",
    "    train = True, # 훈련용 데이터\n",
    "    download = True, # root 경로에 없으면 download\n",
    "    transform = transform # load시 적용할 filters\n",
    ")\n",
    "testset = datasets.FashionMNIST(\n",
    "    root = './.data/',\n",
    "    train = False, # test data\n",
    "    download = True,\n",
    "    transform = transform\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dae3b5c",
   "metadata": {},
   "source": [
    "#### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7e953338",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = data.DataLoader(\n",
    "    dataset = trainset,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,\n",
    ")\n",
    "\n",
    "test_loader = data.DataLoader(\n",
    "    dataset = testset,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de2ad18",
   "metadata": {},
   "source": [
    "아 여기서 의문점이 풀렸다. data를 로드할 당시 batch단위로 로드해왔다. 즉 test_loader 한 단위마다 16개의 이미지가 있는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de03f7f",
   "metadata": {},
   "source": [
    "### Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7a25b3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Test Loss:  0.8468, Accuracy: 68.77%\n",
      "[2] Test Loss:  0.6787, Accuracy: 74.11%\n",
      "[3] Test Loss:  0.5880, Accuracy: 79.43%\n",
      "[4] Test Loss:  0.5567, Accuracy: 79.54%\n",
      "[5] Test Loss:  0.5193, Accuracy: 81.92%\n",
      "[6] Test Loss:  0.5096, Accuracy: 81.39%\n",
      "[7] Test Loss:  0.4862, Accuracy: 82.84%\n",
      "[8] Test Loss:  0.4726, Accuracy: 83.33%\n",
      "[9] Test Loss:  0.4824, Accuracy: 82.55%\n",
      "[10] Test Loss:  0.4798, Accuracy: 82.54%\n",
      "[11] Test Loss:  0.4513, Accuracy: 83.97%\n",
      "[12] Test Loss:  0.4532, Accuracy: 83.84%\n",
      "[13] Test Loss:  0.4400, Accuracy: 84.56%\n",
      "[14] Test Loss:  0.4326, Accuracy: 84.82%\n",
      "[15] Test Loss:  0.4257, Accuracy: 84.73%\n",
      "[16] Test Loss:  0.4237, Accuracy: 84.93%\n",
      "[17] Test Loss:  0.4115, Accuracy: 85.33%\n",
      "[18] Test Loss:  0.4164, Accuracy: 85.14%\n",
      "[19] Test Loss:  0.4530, Accuracy: 83.71%\n",
      "[20] Test Loss:  0.4016, Accuracy: 85.87%\n",
      "[21] Test Loss:  0.3977, Accuracy: 85.95%\n",
      "[22] Test Loss:  0.4105, Accuracy: 85.38%\n",
      "[23] Test Loss:  0.3978, Accuracy: 85.78%\n",
      "[24] Test Loss:  0.3941, Accuracy: 86.08%\n",
      "[25] Test Loss:  0.3866, Accuracy: 86.41%\n",
      "[26] Test Loss:  0.3960, Accuracy: 85.77%\n",
      "[27] Test Loss:  0.3798, Accuracy: 86.72%\n",
      "[28] Test Loss:  0.3841, Accuracy: 86.09%\n",
      "[29] Test Loss:  0.3782, Accuracy: 86.47%\n",
      "[30] Test Loss:  0.3824, Accuracy: 86.12%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(model, train_loader, optimizer)\n",
    "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
    "    \n",
    "    print('[{}] Test Loss: {: .4f}, Accuracy: {:.2f}%'.format(\n",
    "                epoch, test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ef938f",
   "metadata": {},
   "source": [
    "----\n",
    "회고\n",
    "\n",
    "- 2번째 신경망 모델이여서 pytorch로 어떻게 신경망을 구현하는지 조금 익숙해진 듯하다.\n",
    "- 학기 중이라 오랜만에 학습했더니, 이전 내용이 또 흐릿하다. 복습해야 겠다.\n",
    "- batch 학습에 대한 이해가 부족한 것 같다. 추가 학습이 필요해 보인다.\n",
    "- 다음 CNN을 구현하기 이전에 ANN, DNN에 대한 train, test 함수 구현에 초점을 맞춰 리뷰하고 더불어 MNIST를 통해 pytorch로 data 로드하는 방법을 복습해야 겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904faba0",
   "metadata": {},
   "source": [
    "### 과적합과 드롭아웃\n",
    "과적합을 방지하기 위해 아래의 방법을 사용할 수 있다.\n",
    ">- Early Stopping  \n",
    "    검증 세트에서의 성능이 나빠지기 직전에 훈련을 중단한다.\n",
    ">- Data Augmentation\n",
    ">- Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cbc824",
   "metadata": {},
   "source": [
    "#### [1] Image Data Augmentation\n",
    "\n",
    "이미지 데이터는 torchvision에서 제공되는 transforms를 통해 다양한 변주를 주며 데이터 양을 늘릴 수 있다.  \n",
    "노이즈 추가, 이미지 일부 자르기, 돌리기, 색상 변경 등의 변주를 줄 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d528291e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = data.DataLoader(\n",
    "    datasets.FashionMNIST(\n",
    "        './.data',\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = data.DataLoader(\n",
    "    datasets.FashionMNIST(\n",
    "        './.data',\n",
    "        train=False,\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0410dc6a",
   "metadata": {},
   "source": [
    "- transforms.RandomHorizontalFlip() : 무작위로 수평 뒤집기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f26056",
   "metadata": {},
   "source": [
    "#### [2] Dropout\n",
    "모델의 생성자에 dropout 비율을 지정해 설정할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0775005e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, dropout_p=0.2):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 10) # output layer ; multi-class classification\n",
    "        self.dropout_p = dropout_p # 드롭아웃 비율(기본값=0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784) # 1차원 행렬로 변환\n",
    "        x = F.relu(self.fc1(x))     \n",
    "        # 드롭아웃 추가\n",
    "        x = F.dropout(x, training=self.training, # 학습모드 여부\n",
    "                    p=self.dropout_p) # dropout 비율\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.dropout(x, training=self.training, \n",
    "                    p=self.dropout_p) \n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4915bd4b",
   "metadata": {},
   "source": [
    "- forward\n",
    "    - F.dropout(x, training=self.traininig, p=self.dropout_p)\n",
    "    - model의 학습모드 여부 및 dropout 비율 전달"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "670c1e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(dropout_p=0.2).to(DEVICE)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8c4a2e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Test Loss:  0.6544, Accuracy: 76.29%\n",
      "[2] Test Loss:  0.5358, Accuracy: 80.65%\n",
      "[3] Test Loss:  0.4935, Accuracy: 82.28%\n",
      "[4] Test Loss:  0.4629, Accuracy: 83.07%\n",
      "[5] Test Loss:  0.4429, Accuracy: 83.93%\n",
      "[6] Test Loss:  0.4318, Accuracy: 84.45%\n",
      "[7] Test Loss:  0.4286, Accuracy: 84.31%\n",
      "[8] Test Loss:  0.4092, Accuracy: 85.20%\n",
      "[9] Test Loss:  0.3999, Accuracy: 85.47%\n",
      "[10] Test Loss:  0.3925, Accuracy: 85.84%\n",
      "[11] Test Loss:  0.3844, Accuracy: 86.16%\n",
      "[12] Test Loss:  0.3824, Accuracy: 86.14%\n",
      "[13] Test Loss:  0.3704, Accuracy: 86.73%\n",
      "[14] Test Loss:  0.3736, Accuracy: 86.57%\n",
      "[15] Test Loss:  0.3700, Accuracy: 86.66%\n",
      "[16] Test Loss:  0.3602, Accuracy: 86.94%\n",
      "[17] Test Loss:  0.3600, Accuracy: 87.07%\n",
      "[18] Test Loss:  0.3585, Accuracy: 87.02%\n",
      "[19] Test Loss:  0.3542, Accuracy: 87.01%\n",
      "[20] Test Loss:  0.3458, Accuracy: 87.47%\n",
      "[21] Test Loss:  0.3430, Accuracy: 87.52%\n",
      "[22] Test Loss:  0.3492, Accuracy: 87.44%\n",
      "[23] Test Loss:  0.3429, Accuracy: 87.61%\n",
      "[24] Test Loss:  0.3424, Accuracy: 87.78%\n",
      "[25] Test Loss:  0.3478, Accuracy: 87.43%\n",
      "[26] Test Loss:  0.3369, Accuracy: 87.71%\n",
      "[27] Test Loss:  0.3309, Accuracy: 87.95%\n",
      "[28] Test Loss:  0.3308, Accuracy: 88.01%\n",
      "[29] Test Loss:  0.3553, Accuracy: 86.44%\n",
      "[30] Test Loss:  0.3307, Accuracy: 88.09%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(model, train_loader, optimizer)\n",
    "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
    "    \n",
    "    print('[{}] Test Loss: {: .4f}, Accuracy: {:.2f}%'.format(\n",
    "                epoch, test_loss, test_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
